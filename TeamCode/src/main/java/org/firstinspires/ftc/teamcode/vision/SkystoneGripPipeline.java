package org.firstinspires.ftc.teamcode.vision;

import android.graphics.Bitmap;

import com.acmerobotics.dashboard.FtcDashboard;
import com.acmerobotics.dashboard.config.Config;
import com.acmerobotics.dashboard.telemetry.TelemetryPacket;
import com.qualcomm.robotcore.hardware.HardwareMap;
import com.vuforia.Image;
import com.vuforia.PIXEL_FORMAT;
import com.vuforia.Vuforia;

import org.firstinspires.ftc.robotcore.external.ClassFactory;
import org.firstinspires.ftc.robotcore.external.Telemetry;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaLocalizer;
import org.firstinspires.ftc.teamcode.RC;
import org.firstinspires.ftc.teamcode.statemachine.MineralStateProvider;
import org.firstinspires.ftc.teamcode.util.BlobStats;
import org.firstinspires.ftc.teamcode.util.VisionUtils;
import org.firstinspires.ftc.teamcode.vision.colorblob.ColorBlobDetector;
import org.opencv.android.Utils;
import org.opencv.core.*;
import org.opencv.features2d.Features2d;
//import org.opencv.features2d.SimpleBlobDetector;
import org.opencv.imgproc.*;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.concurrent.BlockingQueue;

/**
 * GripPipeline class.
 *
 * <p>An OpenCV pipeline generated by GRIP.
 *
 * @author GRIP
 */

@Config
public class SkystoneGripPipeline implements SkystoneVisionProvider {

    //vuforia
    private VuforiaLocalizer vuforia;
    private BlockingQueue<VuforiaLocalizer.CloseableFrame> q;
    private VuforiaLocalizer.CloseableFrame frame;

    //statistics
    private SkystoneTargetInfo target;
    List<MatOfPoint> contours = new ArrayList<MatOfPoint>();
    List<BlobStats> blobs = new ArrayList<BlobStats>();

    //pivs
    private boolean redAlliance;
    private boolean enableDashboard;
    private int state = -1;
    private Mat mat, overlay;

    //cropping
    public static Point
            TOP_LEFT_RED = new Point(130, 225),
            BOTTOM_RIGHT_RED = new Point(564, 371),
            TOP_LEFT_BLUE = new Point(133, 148),
            BOTTOM_RIGHT_BLUE = new Point(420, 234);

    //debugging
    private Telemetry telemetry;
    private FtcDashboard dashboard;

    //tuned constants
    public static int LEFT_BOUND = 575, RIGHT_BOUND = 1100;
    public static double BLUR_RADIUS = 19.82;
    public static double[][] HSV_THRESHOLD_PARAMETERS = {
            {0.0, 180},
            {0.0, 255.0},
            {4.586, 91.867}
    };


    private void initVuforia(HardwareMap hardwareMap, Viewpoint viewpoint) {
        VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters();
        parameters.vuforiaLicenseKey = RC.VUFORIA_LICENSE_KEY;
        if (viewpoint == Viewpoint.BACK)
            parameters.cameraDirection = VuforiaLocalizer.CameraDirection.BACK;
        else if (viewpoint == Viewpoint.WEBCAM)
            parameters.cameraName = hardwareMap.get(WebcamName.class, "Webcam 1");
        else
            parameters.cameraDirection = VuforiaLocalizer.CameraDirection.FRONT;
        vuforia = ClassFactory.getInstance().createVuforia(parameters);
        Vuforia.setFrameFormat(PIXEL_FORMAT.RGB565, true);
        vuforia.setFrameQueueCapacity(1);
    }

    @Override
    public void initializeVision(HardwareMap hardwareMap, Telemetry telemetry, boolean enableDashboard, Viewpoint viewpoint, boolean redAlliance) {
        initVuforia(hardwareMap, viewpoint);
        q = vuforia.getFrameQueue();
        state = 0;
        target = new SkystoneTargetInfo();
        this.redAlliance = redAlliance;
        this.telemetry = telemetry;
        this.enableDashboard = enableDashboard;
        if (enableDashboard)
            dashboard = FtcDashboard.getInstance();
    }

    @Override
    public void shutdownVision() {
    }

    @Override
    public void reset() {
        state = 0;
    }

    @Override
    public SkystoneTargetInfo detectSkystone() {
//        telemetry.addData("OpenCV State Machine State", state);
        switch (state) {
            case 0:
                if (q.isEmpty()) {
                    target.confidence = 0;
                    target.finished = false;
                    return target;
                }

                VuforiaLocalizer.CloseableFrame frame;
                try {
                    frame = q.take();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                }
                Image img = VisionUtils.getImageFromFrame(frame, PIXEL_FORMAT.RGB565);
                Bitmap bm = Bitmap.createBitmap(img.getWidth(), img.getHeight(), Bitmap.Config.RGB_565);
                bm.copyPixelsFromBuffer(img.getPixels());
                mat = VisionUtils.bitmapToMat(bm, CvType.CV_8UC3);
                overlay = VisionUtils.bitmapToMat(bm, CvType.CV_8UC3);
                break;
            case 1:
                blur(mat, BLUR_RADIUS, overlay);
                if (redAlliance)
                    overlay = crop(overlay, TOP_LEFT_RED, BOTTOM_RIGHT_RED);
                else
                    overlay = crop(overlay, TOP_LEFT_BLUE, BOTTOM_RIGHT_BLUE);
                hsvThreshold(overlay, HSV_THRESHOLD_PARAMETERS, overlay);
                break;
            case 2:
                List<MatOfPoint> contours = new ArrayList<>();
                Imgproc.findContours(overlay, contours, new Mat(), Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

                // Find max contour area
                double maxArea = 0;
                Iterator<MatOfPoint> each = contours.iterator();
                while (each.hasNext()) {
                    MatOfPoint wrapper = each.next();
                    double area = Imgproc.contourArea(wrapper);
                    if (area > maxArea)
                        maxArea = area;
                }

                // Filter contours by area and resize to fit the original image size
                this.contours.clear();
                each = contours.iterator();
                while (each.hasNext()) {
                    MatOfPoint contour = each.next();
                    if (Imgproc.contourArea(contour) > 0.1 * maxArea) {
                        Core.multiply(contour, new Scalar(4, 4), contour);
                        this.contours.add(contour);
                        Moments p = Imgproc.moments(contour, false);
                        int x = (int) (p.get_m10() / p.get_m00());
                        int y = (int) (p.get_m01() / p.get_m00());
                        double area = Imgproc.contourArea(contour);
                        org.opencv.core.Rect blobBox = Imgproc.boundingRect(contour);
                        BlobStats blob = new BlobStats(p, x, y, blobBox.width, blobBox.height, area);
                        blobs.add(blob);
                        Imgproc.circle(overlay, new Point(x, y), 5, new Scalar(0, 255, 0, 255), 5);
                    }
                    Imgproc.drawContours(overlay, contours, -1, new Scalar(0, 255, 0, 255), 3);
                }
                break;
            case 3:
                if (!enableDashboard)
                    break;
                Bitmap overlayBitmap = Bitmap.createBitmap(overlay.width(), overlay.height(), Bitmap.Config.RGB_565);
                Utils.matToBitmap(overlay, overlayBitmap);
                dashboard.sendImage(overlayBitmap);
                overlay.release();
                break;
            case 4:
                BlobStats largestBlob = null;
                for (BlobStats blobStats : blobs) {
                    if (largestBlob == null)
                        largestBlob = blobStats;
                    else if (blobStats.area > largestBlob.area)
                        largestBlob = blobStats;
                }

                if (largestBlob == null) {
                    target.confidence = 0;
                    target.finished = false;
                    return target;
                }

                target.centroidX = largestBlob.x;
                target.centroidY = largestBlob.y;
                target.width = largestBlob.width;
                target.height = largestBlob.height;

                if (largestBlob.x < LEFT_BOUND)
                    target.quarryPosition = !redAlliance ? StonePos.NORTH : StonePos.SOUTH;
                else if (largestBlob.x < RIGHT_BOUND)
                    target.quarryPosition = StonePos.MIDDLE;
                else
                    target.quarryPosition = redAlliance ? StonePos.NORTH : StonePos.SOUTH;

                target.confidence = 1;
                return target;
            default:
                target.confidence = 0;
                target.finished = false;
                return target;
        }
        state++;
        target.confidence = 0;
        target.finished = false;
        return target;
    }

    private void blur(Mat input, double doubleRadius, Mat output) {
        int radius = (int)(doubleRadius + 0.5);
        int kernelSize;
        kernelSize = 6 * radius + 1;
        Imgproc.GaussianBlur(input,output, new Size(kernelSize, kernelSize), radius);
    }

    private void hsvThreshold(Mat input, double[][] threshold, Mat out) {
        Imgproc.cvtColor(input, out, Imgproc.COLOR_BGR2HSV);
        Core.inRange(out,
                new Scalar(threshold[0][0], threshold[1][0], threshold[2][0]),
                new Scalar(threshold[0][1], threshold[1][1], threshold[2][1]),
                out);
    }

    private Mat crop(Mat image, Point topLeftCorner, Point bottomRightCorner) {
        Rect cropRect = new Rect(topLeftCorner, bottomRightCorner);
        return new Mat(image, cropRect);
    }
}
