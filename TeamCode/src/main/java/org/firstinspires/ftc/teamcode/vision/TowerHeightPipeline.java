package org.firstinspires.ftc.teamcode.vision;

import android.graphics.Bitmap;

import com.acmerobotics.dashboard.FtcDashboard;
import com.acmerobotics.dashboard.telemetry.TelemetryPacket;
import com.qualcomm.robotcore.hardware.HardwareMap;
import com.vuforia.Image;
import com.vuforia.PIXEL_FORMAT;
import com.vuforia.Vuforia;

import org.firstinspires.ftc.robotcore.external.ClassFactory;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaLocalizer;
import org.firstinspires.ftc.teamcode.RC;
import org.firstinspires.ftc.teamcode.statemachine.MineralStateProvider;
import org.firstinspires.ftc.teamcode.util.BlobStats;
import org.firstinspires.ftc.teamcode.util.VisionUtils;
import org.opencv.android.Utils;
import org.opencv.core.*;
import org.opencv.features2d.Features2d;
import org.opencv.features2d.SimpleBlobDetector;
import org.opencv.imgproc.*;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.concurrent.BlockingQueue;

import static org.firstinspires.ftc.teamcode.vision.Config.*;

/**
 * GripPipeline class.
 *
 * <p>An OpenCV pipeline generated by GRIP.
 *
 * @author GRIP
 */
public class TowerHeightPipeline {

    //Outputs
    private Mat blurOutput = new Mat();
    private Mat hsvThresholdOutput = new Mat();

    //vuforia
    private VuforiaLocalizer vuforia;
    private BlockingQueue<VuforiaLocalizer.CloseableFrame> q;
    VuforiaLocalizer.CloseableFrame frame;

    //Statistics
    public List<BlobStats> blobs = new ArrayList<BlobStats>();
    public List<MatOfPoint> mContours = new ArrayList<MatOfPoint>();
    public int towerWidth, towerHeight, blocks, x;
    public double aspectRatio;
    public FtcDashboard dashboard;

    //contants
    public static final double[] ASPECT_RATIOS  = {0.3325, 0.8775, 1.2575, 1.6375, 2.0425, 2.4, 2.7325};

    public TowerHeightPipeline(HardwareMap hardwareMap, VuforiaLocalizer vuforia) {
        this.vuforia = vuforia;
        q = vuforia.getFrameQueue();
        dashboard = FtcDashboard.getInstance();
    }

    /**
     * This is the primary method that runs the entire pipeline and updates the outputs.
     */
    public Mat process() {
        if (!q.isEmpty()) {
            try {
                frame = q.take();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            Image img = VisionUtils.getImageFromFrame(frame, PIXEL_FORMAT.RGB565);
            Bitmap bm = Bitmap.createBitmap(img.getWidth(), img.getHeight(), Bitmap.Config.RGB_565);
            bm.copyPixelsFromBuffer(img.getPixels());

            Mat mat = new Mat(bm.getWidth(), bm.getHeight(), CvType.CV_8UC4);
            Utils.bitmapToMat(bm, mat);

            // Step Blur0:
            Mat blurInput = mat;
            BlurType blurType = BlurType.get("Gaussian Blur");
            double blurRadius = 9.81981981981982;
            blur(blurInput, blurType, blurRadius, blurOutput);

            // Step HSV_Threshold0:
            Mat hsvThresholdInput = blurOutput.clone();
            double[] hsvThresholdHue = {H_MIN, H_MAX};
            double[] hsvThresholdSaturation = {S_MIN, S_MAX};
            double[] hsvThresholdValue = {V_MIN, V_MAX};
            hsvThreshold(hsvThresholdInput, hsvThresholdHue, hsvThresholdSaturation, hsvThresholdValue, hsvThresholdOutput);

            // Filter contours by area and resize to fit the original image size

            Mat contoursInput = hsvThresholdOutput;
            List<MatOfPoint> contours = new ArrayList<MatOfPoint>();
            List<BlobStats> blobs = new ArrayList<BlobStats>();

            Imgproc.findContours(contoursInput, contours, new Mat(), Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

            // Find max contour area
            double maxArea = 0;
            Iterator<MatOfPoint> each = contours.iterator();
            while (each.hasNext()) {
                MatOfPoint wrapper = each.next();
                double area = Imgproc.contourArea(wrapper);
                if (area > maxArea)
                    maxArea = area;
            }

            // Filter contours by area and resize to fit the original image size
            mContours.clear();
            each = contours.iterator();
            while (each.hasNext()) {
                MatOfPoint contour = each.next();
                if (Imgproc.contourArea(contour) > 0.1 * maxArea) {
                    Core.multiply(contour, new Scalar(4, 4), contour);
                    mContours.add(contour);
                    Moments p = Imgproc.moments(contour, false);
                    int x = (int) (p.get_m10() / p.get_m00());
                    int y = (int) (p.get_m01() / p.get_m00());
                    double area = Imgproc.contourArea(contour);
                    org.opencv.core.Rect blobBox = Imgproc.boundingRect(contour);
                    BlobStats blob = new BlobStats(p, x, y, blobBox.width, blobBox.height, area);
                    blobs.add(blob); //put it in the List
                    Imgproc.circle(hsvThresholdOutput, new Point(x, y), 5, new Scalar(0, 255, 0, 255), 5);
                }
                Imgproc.drawContours(hsvThresholdOutput, mContours, -1, new Scalar(0, 255, 0, 255), 3);
            }

            if(!blobs.isEmpty()) {
                BlobStats mainBlob = blobs.get(blobs.size() - 1);

                towerWidth = mainBlob.width;
                towerHeight = mainBlob.height;
                aspectRatio = (double) towerHeight / towerWidth;
                x = mainBlob.x;

                if(aspectRatio < ASPECT_RATIOS[0])
                    blocks = 0;
                else if(aspectRatio < ASPECT_RATIOS[1])
                    blocks = 1;
                else if(aspectRatio < ASPECT_RATIOS[2])
                    blocks = 2;
                else if(aspectRatio < ASPECT_RATIOS[3])
                    blocks = 3;
                else if(aspectRatio < ASPECT_RATIOS[4])
                    blocks = 4;
                else if(aspectRatio < ASPECT_RATIOS[5])
                   blocks = 5;
                else if(aspectRatio < ASPECT_RATIOS[6])
                    blocks = 6;
                else
                    blocks = 7;
            }

            this.blobs = blobs;
            return hsvThresholdOutput;
        }
        return null;
    }

    /**
     * An indication of which type of filter to use for a blur.
     * Choices are BOX, GAUSSIAN, MEDIAN, and BILATERAL
     */
    enum BlurType{
        BOX("Box Blur"), GAUSSIAN("Gaussian Blur"), MEDIAN("Median Filter"),
        BILATERAL("Bilateral Filter");

        private final String label;

        BlurType(String label) {
            this.label = label;
        }

        public static BlurType get(String type) {
            if (BILATERAL.label.equals(type)) {
                return BILATERAL;
            }
            else if (GAUSSIAN.label.equals(type)) {
                return GAUSSIAN;
            }
            else if (MEDIAN.label.equals(type)) {
                return MEDIAN;
            }
            else {
                return BOX;
            }
        }

        @Override
        public String toString() {
            return this.label;
        }
    }

    /**
     * Softens an image using one of several filters.
     * @param input The image on which to perform the blur.
     * @param type The blurType to perform.
     * @param doubleRadius The radius for the blur.
     * @param output The image in which to store the output.
     */
    private void blur(Mat input, BlurType type, double doubleRadius,
                      Mat output) {
        int radius = (int)(doubleRadius + 0.5);
        int kernelSize;
        switch(type){
            case BOX:
                kernelSize = 2 * radius + 1;
                Imgproc.blur(input, output, new Size(kernelSize, kernelSize));
                break;
            case GAUSSIAN:
                kernelSize = 6 * radius + 1;
                Imgproc.GaussianBlur(input,output, new Size(kernelSize, kernelSize), radius);
                break;
            case MEDIAN:
                kernelSize = 2 * radius + 1;
                Imgproc.medianBlur(input, output, kernelSize);
                break;
            case BILATERAL:
                Imgproc.bilateralFilter(input, output, -1, radius, radius);
                break;
        }
    }

    /**
     * Segment an image based on hue, saturation, and value ranges.
     *
     * @param input The image on which to perform the HSL threshold.
     * @param hue The min and max hue
     * @param sat The min and max saturation
     * @param val The min and max value
     * @param out The image in which to store the output.
     */
    private void hsvThreshold(Mat input, double[] hue, double[] sat, double[] val,
                              Mat out) {
        Imgproc.cvtColor(input, out, Imgproc.COLOR_BGR2HSV);
        Core.inRange(out, new Scalar(hue[0], sat[0], val[0]),
                new Scalar(hue[1], sat[1], val[1]), out);
    }
}
